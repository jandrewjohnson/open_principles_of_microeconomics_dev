{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Machine Learning Intro\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Cross-Validation, Python for Linear Regression, and Support Vector Machines\n",
    "\n",
    "\n",
    "\n",
    "Reminder as always: Pull the latest code (I probably made some minor updates)\n",
    "\n",
    "\n",
    "\n",
    "Related fun OSS product of the day: QUARTO\\!\n",
    "\n",
    "\n",
    "\n",
    "# Syllabus check-in\n",
    "\n",
    "\n",
    "\n",
    "![](img\\\\1219.png)\n",
    "\n",
    "\n",
    "\n",
    "I've also added some optional journal articles to Canvas that exemplify the approaches we're using\n",
    "\n",
    "\n",
    "\n",
    "# Agenda\n",
    "\n",
    "\n",
    "\n",
    "Final word on Git: pushing and pulling\\.\n",
    "\n",
    "\n",
    "\n",
    "Discuss cross\\-validation \\(CV\\) vs\\. model performance\n",
    "\n",
    "\n",
    "\n",
    "Introduce Scikit\\-learn via regular linear regression\\, use it to talk about CV\n",
    "\n",
    "\n",
    "\n",
    "Introduce Support Vector Machines for classification\n",
    "\n",
    "\n",
    "\n",
    "# Git push and pull\n",
    "\n",
    "\n",
    "\n",
    "# What happens when I make a change and how does everyone stay synced.\n",
    "\n",
    "\n",
    "\n",
    "# Suppose I make an edit on my Workstation\n",
    "\n",
    "\n",
    "\n",
    "Suppose I ad some extremely important new code to our workbook from last lecture\\.\n",
    "\n",
    "\n",
    "\n",
    "![](img\\\\1220.png)\n",
    "\n",
    "\n",
    "\n",
    "# Git realizes that my file now doesn't match the repository\n",
    "\n",
    "\n",
    "\n",
    "First thing you'll notice is the file changes to brown/orange and has an \"M\" for modified by it\\.\n",
    "\n",
    "\n",
    "\n",
    "# How do I get this into the online repository?\n",
    "\n",
    "\n",
    "\n",
    "* Click on the Source Control tab and you will see this file listed in the \"Change List\"\n",
    "\n",
    "* Because I'm in charge of this repository\\, I want to \"commit\" this file and then \"push\" it to the repository\\.\n",
    "\n",
    "  * I type a commit message \\(REQUIRED and will silently fail if not\\)\\, and then select Commit and Push\\.\n",
    "\n",
    "* Now my Source Control tab is clean\\. That means my local code matches the remote repository\\.\n",
    "\n",
    "\n",
    "\n",
    "![](img\\\\1221.png)\n",
    "\n",
    "\n",
    "\n",
    "![](img\\\\1222.png)\n",
    "\n",
    "\n",
    "\n",
    "# But wait, what happens to other people who also have edited the file?\n",
    "\n",
    "\n",
    "\n",
    "Gitting into a predicament\\.\n",
    "\n",
    "\n",
    "\n",
    "# Suppose your instructor says \"okay, now pull the latest code from the course repository�\"\n",
    "\n",
    "\n",
    "\n",
    "* If you do that\\, VS Code might scold you\\.\n",
    "\n",
    "* What does this mean?\n",
    "\n",
    "* It means YOU have changes on your computer that are different from what's on GitHub\\.\n",
    "\n",
    "  * Git can't pull because it doesn't know how to resolve the conflict\\.\n",
    "\n",
    "\n",
    "\n",
    "![](img\\\\1223.png)\n",
    "\n",
    "\n",
    "\n",
    "# Source control tab shows new code is available.\n",
    "\n",
    "\n",
    "\n",
    "Go to the Source Control tab\n",
    "\n",
    "\n",
    "\n",
    "If your files are different than the repository\\, you will see those files listed here\\.\n",
    "\n",
    "\n",
    "\n",
    "# How do we resolve this \"merge conflict\"?\n",
    "\n",
    "\n",
    "\n",
    "![](img\\\\1224.png)\n",
    "\n",
    "\n",
    "\n",
    "If you do not want to keep your changes \\(simplest case\\) we can discard them and then pull\\.\n",
    "\n",
    "\n",
    "\n",
    "To do this\\, go to the Source Control tab and you will see the Change List\\.\n",
    "\n",
    "\n",
    "\n",
    "Right\\-click\\, and select discard changes\\.\n",
    "\n",
    "\n",
    "\n",
    "Now you can happily Git Pull\\.\n",
    "\n",
    "\n",
    "\n",
    "![](img\\\\1225.png)\n",
    "\n",
    "\n",
    "\n",
    "# You can also keep both sets of changes by \"merging\" them\n",
    "\n",
    "\n",
    "\n",
    "![](img\\\\1226.png)\n",
    "\n",
    "\n",
    "\n",
    "Here's an example where I might want to keep them\\.\n",
    "\n",
    "\n",
    "\n",
    "I clicked on the change list and opened it\\. You can see where I modified the In\\-class exercise\\.\n",
    "\n",
    "\n",
    "\n",
    "You can research more about this on your own\\, but for now we're just going to avoid it\\.\n",
    "\n",
    "\n",
    "\n",
    "# I think the best way to do this is to just move this to your own folder outside the repository.\n",
    "\n",
    "\n",
    "\n",
    "![](img\\\\1227.png)\n",
    "\n",
    "\n",
    "\n",
    "There you can preserve all your notes\\.\n",
    "\n",
    "\n",
    "\n",
    "Once you moved the file \\(not copied\\)\\, Git Pull will succeed at getting the newest course code\\.\n",
    "\n",
    "\n",
    "\n",
    "# Cross-validation\n",
    "\n",
    "\n",
    "\n",
    "In my opinion\\, this is the most important advance in all of Machine Learning from the perspective of an applied economist\\.\n",
    "\n",
    "\n",
    "\n",
    "# Cross-validation vs model performance\n",
    "\n",
    "\n",
    "\n",
    "* In either econometrics or ML\\, there are two tasks in building a model\n",
    "\n",
    "  * Estimating parameters of the model\n",
    "\n",
    "  * Evaluating how well that model does\n",
    "\n",
    "* Different approaches for these steps between Econometrics and ML:\n",
    "\n",
    "  * Econometrics the above steps involve:\n",
    "\n",
    "    * t\\- and p\\-statistics\\, hypothesis testing\\, analyzing specific coefficients\n",
    "\n",
    "    * R\\-values\\, AIC/BIC\\, etc\n",
    "\n",
    "  * In ML\\, the emphasis is different\\. The above steps in ML are:\n",
    "\n",
    "    * Mostly absent in isolation\\, but included in step 2\\.\n",
    "\n",
    "    * Determined by cross\\-validation of the model\\.\n",
    "\n",
    "\n",
    "\n",
    "# Returning to the complexity tradeoff.\n",
    "\n",
    "\n",
    "\n",
    "* Recall: Overfitting a model is making the model overly complex to that accuracy falls on the test data\\.\n",
    "\n",
    "  * We will talk about ways to methodologically hit the \"sweet spot\" of model complexity\\.\n",
    "\n",
    "* How do we find this sweet\\-spot? Cross validation\n",
    "\n",
    "* _First though\\, let's illustrate why overly\\-complex models can UNDER\\-perform\\._\n",
    "\n",
    "\n",
    "\n",
    "![](img\\\\1228.png)\n",
    "\n",
    "\n",
    "\n",
    "The source of the \"sweet spot\" in model complexity\\.\n",
    "\n",
    "\n",
    "\n",
    "![](img\\\\1229.png)\n",
    "\n",
    "\n",
    "\n",
    "The complex model is super accurate on the training data\\.\n",
    "\n",
    "\n",
    "\n",
    "![](img\\\\1230.png)\n",
    "\n",
    "\n",
    "\n",
    "With new data\\, the complex model is much worse\\. Notice that the simple model performs about the same\\.\n",
    "\n",
    "\n",
    "\n",
    "Image source: statquest\\.org\n",
    "\n",
    "\n",
    "\n",
    "# Operationalizing Cross-Validation\n",
    "\n",
    "\n",
    "\n",
    "# Splitting data and Cross-Validation\n",
    "\n",
    "\n",
    "\n",
    "![](img\\\\1231.png)\n",
    "\n",
    "\n",
    "\n",
    "* In this course\\, we will use scikit\\-learn to illustrate this\\.\n",
    "\n",
    "* Scikit\\-learn has nice built\\-in functions to split our data into training and test data\\.\n",
    "\n",
    "  * This is the first step of cross\\-validation approaches\\.\n",
    "\n",
    "* We are going to set aside the data and make sure we never use it again until the very end\\.\n",
    "\n",
    "\n",
    "\n",
    "# We train the model on a second split of the data\n",
    "\n",
    "\n",
    "\n",
    "![](img\\\\1232.png)\n",
    "\n",
    "\n",
    "\n",
    "* To train our model\\, cross\\-validation creates a second split of the training data\\.\n",
    "\n",
    "  * ML algorithms will iteratively try different models/coefficients on this second spit\\, using whichever performs best on the training\\-test data\\.\n",
    "\n",
    "  * But we can do MORE than that\\!\n",
    "\n",
    "\n",
    "\n",
    "![](img\\\\1233.png)\n",
    "\n",
    "\n",
    "\n",
    "# Splitting into MANY Splits and Folds\n",
    "\n",
    "\n",
    "\n",
    "![](img\\\\1234.png)\n",
    "\n",
    "\n",
    "\n",
    "# Final model performance analysis\n",
    "\n",
    "\n",
    "\n",
    "![](img\\\\1235.png)\n",
    "\n",
    "\n",
    "\n",
    "* Once the best set of parameters are found\\, the model is compared against the test data from the first split\\.\n",
    "\n",
    "* Final performance assessment then is done with calculating the MSE of the model prediction of Test\\_X for Test\\_Y\n",
    "\n",
    "* This method is SUPER FLEXIBLE\n",
    "\n",
    "  * It could compare totally dissimilar models in a rigorous way\\.\n",
    "\n",
    "  * Will helps us choose \"tuning\\-\" or \"hyper\\-parameters\"\n",
    "\n",
    "\n",
    "\n",
    "# Switch to VS Code\n",
    "\n",
    "\n",
    "\n",
    "Open Lectures\\\\02\\_Machine\\_Learning\\\\01\\_Linear\\_Regression\\.ipynb\n",
    "\n",
    "\n",
    "\n",
    "# Support Vector Machines\n",
    "\n",
    "\n",
    "\n",
    "# Support vector machines\n",
    "\n",
    "\n",
    "\n",
    "Motivation: classify inputs into categories\n",
    "\n",
    "\n",
    "\n",
    "Approach: draw a line \\(hyperplane\\) separating observations from different categories\n",
    "\n",
    "\n",
    "\n",
    "Issue 1: Many lines might work\\. Which one should we choose?\n",
    "\n",
    "\n",
    "\n",
    "Issue 1: Many lines might work\\. Which one should we choose?\n",
    "\n",
    "\n",
    "\n",
    "A: Pick the line with the largest 'margin' � distance to nearest points on either side\n",
    "\n",
    "\n",
    "\n",
    "# SVMs: naming digression\n",
    "\n",
    "\n",
    "\n",
    "Those nearest points determine the 'support vectors'\\. I think of it as a little person heroically holding up the margin lines\\.\n",
    "\n",
    "\n",
    "\n",
    "![](img\\\\1236.png)\n",
    "\n",
    "\n",
    "\n",
    "![](img\\\\1237.png)\n",
    "\n",
    "\n",
    "\n",
    "# SVM: math preliminaries\n",
    "\n",
    "\n",
    "\n",
    "![](img\\\\1238.png)\n",
    "\n",
    "\n",
    "\n",
    "# SVM: objective\n",
    "\n",
    "\n",
    "\n",
    "# Support vector machines\n",
    "\n",
    "\n",
    "\n",
    "But\\, maybe no lines work perfectly\\. What can we do?\n",
    "\n",
    "\n",
    "\n",
    "# SVM: objective\n",
    "\n",
    "\n",
    "\n",
    "where add some sort of penalty on misclassifications\\.\n",
    "\n",
    "\n",
    "\n",
    "Many forms of this penalty term are possible\\. Here is the simplest one that just says limit sum of misclassification to be below some threshold gamma\\.\n",
    "\n",
    "\n",
    "\n",
    "You might be wondering\\, wouldn't this all depend on the gamma value?\n",
    "\n",
    "\n",
    "\n",
    "Yes it does\\. And we will use Cross\\-validation to find the best value for this \"hyperparameter\"\\.\n",
    "\n",
    "\n",
    "\n",
    "# We choose gamma via CV!\n",
    "\n",
    "\n",
    "\n",
    "![](img\\\\1239.png)\n",
    "\n",
    "\n",
    "\n",
    "* Iteratively try all values of gamma\\.\n",
    "\n",
    "* Whichever one predicts best across the many splits is what we will use\\.\n",
    "\n",
    "* Thus\\, we have systematically determined exactly how many outliers we  __should__  ignore\n",
    "\n",
    "  * From the perspective of out\\-of\\-sample performance\\.\n",
    "\n",
    "\n",
    "\n",
    "# Switch to VS Code\n",
    "\n",
    "\n",
    "\n",
    "Open Lectures\\\\02\\_Machine\\_Learning\\\\02\\_SVM\\.ipynb\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('8222env1')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 | packaged by conda-forge | (main, Nov 22 2022, 08:16:33) [MSC v.1929 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "0db313e0ad7b6749a6d098fb61fddaded88cbd823278030b75fa0893942c8f77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
