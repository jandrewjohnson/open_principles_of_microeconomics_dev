{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Last day of class!\n",
    "\n",
    "\n",
    "\n",
    "# Before the storm\n",
    "\n",
    "\n",
    "\n",
    "# Agenda\n",
    "\n",
    "\n",
    "\n",
    "* Logistical note: scores for all submitted assignments should be up to date \\(check Canvas to see if everything looks as expected\\)\n",
    "\n",
    "* Discuss two current events that are shaking the world\n",
    "\n",
    "* Two final ML Big\\-data models\n",
    "\n",
    "  * Regression trees\n",
    "\n",
    "  * Na�ve Bayes classification\n",
    "\n",
    "* Integrating R and Python in one environment\n",
    "\n",
    "\n",
    "\n",
    "![](img\\\\1293.png)\n",
    "\n",
    "\n",
    "\n",
    "# AI/ML hits the mainstream\n",
    "\n",
    "\n",
    "\n",
    "# ChatGPT\n",
    "\n",
    "\n",
    "\n",
    "* The chatbot is a large language model that can \"predict\" the best words to respond to any prompt\\.\n",
    "\n",
    "  * Based on OpenAI's GPT\\-3\\.5 model\n",
    "\n",
    "  * The model includes 175 billion parameters \\(requiring 800 GB of storage\\)\\.\n",
    "\n",
    "* <span style=\"color:#000000\">Uses reinforcement learning on a recurrent</span>  neural network\n",
    "\n",
    "* <span style=\"color:#FF0000\">What does this change for us?</span>\n",
    "\n",
    "\n",
    "\n",
    "![](img\\\\1294.png)\n",
    "\n",
    "\n",
    "\n",
    "![](img\\\\1295.png)\n",
    "\n",
    "\n",
    "\n",
    "# Example using Assignment 1\n",
    "\n",
    "\n",
    "\n",
    "# What have we done?!\n",
    "\n",
    "\n",
    "\n",
    "* In the very least\\, this course has prepped you with the tools to understand and leverage this\\.\n",
    "\n",
    "  * For example\\, here's a tutorial that uses almost exactly our Python setup to create their own Chatbot:\n",
    "\n",
    "    * [https://www\\.youtube\\.com/watch?v=C\\-8sF81k7cY](https://www.youtube.com/watch?v=C-8sF81k7cY)\n",
    "\n",
    "  * Based on this tutorial:\n",
    "\n",
    "    * [https://jman4190\\.medium\\.com/how\\-to\\-build\\-a\\-gpt\\-3\\-chatbot\\-with\\-python\\-7b83e55805e6](https://jman4190.medium.com/how-to-build-a-gpt-3-chatbot-with-python-7b83e55805e6)\n",
    "\n",
    "\n",
    "\n",
    "# Classification of land-use, land-cover\n",
    "\n",
    "\n",
    "\n",
    "# From raw sentinel reflectance data\n",
    "\n",
    "\n",
    "\n",
    "# Some machine learning approaches retain \"understandability\"\n",
    "\n",
    "\n",
    "\n",
    "* Throughout this course we've seen applications of satellite data\n",
    "\n",
    "  * Often\\, we don't use the raw reflectance data\n",
    "\n",
    "  * Instead\\, we use a \"remote sensing product\" like land\\-use\\, land\\-cover \\(LULC\\) maps\\.\n",
    "\n",
    "* Most LULC maps are created by some form of a \"regression tree\" based approach\n",
    "\n",
    "  * We'll talk through those in a moment\n",
    "\n",
    "  * For now\\, though\\, I want to keep it simple with a highly \"understandable\" model: Na�ve Bayes\\.\n",
    "\n",
    "\n",
    "\n",
    "# Na�ve Bayes\n",
    "\n",
    "\n",
    "\n",
    "![](img\\\\1296.png)\n",
    "\n",
    "\n",
    "\n",
    "# Recommended reading\n",
    "\n",
    "\n",
    "\n",
    "<span style=\"color:#123654\">Johnson\\, B\\. A\\.\\, & Iizuka\\, K\\. \\(2016\\)\\. Integrating OpenStreetMap crowdsourced data and Landsat time\\-series imagery for rapid land use/land cover \\(LULC\\) mapping: Case study of the Laguna de Bay area of the Philippines\\. Applied Geography\\, 67\\, 140\\-149\\.</span>\n",
    "\n",
    "\n",
    "\n",
    "<span style=\"color:#337AB7\"> _[Breiman](http://link.springer.com/article/10.1023/A:1010933404324)_ </span>  <span style=\"color:#337AB7\"> _[\\, Leo\\. 2001\\. Random Forests\\. Machine Learning 45\\-1: 5\\-32\\.](http://link.springer.com/article/10.1023/A:1010933404324)_ </span>\n",
    "\n",
    "\n",
    "\n",
    "# LULC classification example\n",
    "\n",
    "\n",
    "\n",
    "Open up 04\\_Random\\_Forests/01\\_lulc\\_classification\\.ipynb\n",
    "\n",
    "\n",
    "\n",
    "# Regression trees and Random forests!\n",
    "\n",
    "\n",
    "\n",
    "# But first, a quick break for Student Evaluation of Instructor.\n",
    "\n",
    "\n",
    "\n",
    "# What are these trees?\n",
    "\n",
    "\n",
    "\n",
    "# Regression trees\n",
    "\n",
    "\n",
    "\n",
    "View as decision tree\n",
    "\n",
    "\n",
    "\n",
    "View as partition\n",
    "\n",
    "\n",
    "\n",
    "# Building trees: approach\n",
    "\n",
    "\n",
    "\n",
    "In the most basic implementation\\, pretty much a brute force approach:\n",
    "\n",
    "\n",
    "\n",
    "Start with a tree with one leaf\\, and compute \"loss\" \\(prediction error or impurity\\)\n",
    "\n",
    "\n",
    "\n",
    "For each variable and each possible split point for that variable\\, try splitting\\, compute loss again\\.\n",
    "\n",
    "\n",
    "\n",
    "Pick the best possible split from the previous step\\. Compare to current loss\\. If the improvement outweighs a complexity penalty\\, split\\. Otherwise stop\\.\n",
    "\n",
    "\n",
    "\n",
    "Repeat 1\\-3 for each leaf in the new tree\n",
    "\n",
    "\n",
    "\n",
    "View as decision tree\n",
    "\n",
    "\n",
    "\n",
    "# Moving beyond a tree\n",
    "\n",
    "\n",
    "\n",
    "* Trees are very flexible and intuitive\\, but not without their problems:\n",
    "\n",
    "  * Can be sensitive to input data � changing a point can give different splits\\, etc\n",
    "\n",
    "  * Most functions we're trying to learn aren't really step functions\\, are they?\n",
    "\n",
    "  * How do we quantify uncertainty?\n",
    "\n",
    "* Much of this can be addressed with bootstrapping\\.\n",
    "\n",
    "\n",
    "\n",
    "# Bootstrap reminder\n",
    "\n",
    "\n",
    "\n",
    "* For a sample with n observations:\n",
    "\n",
    "  * Create a bootstrap sample b by sampling n data points  _with replacement_  _ _ from our data\n",
    "\n",
    "  * Estimate the model on b\n",
    "\n",
    "  * Average the estimates over B bootstrap samples\\, and use that for SE estimation too\n",
    "\n",
    "\n",
    "\n",
    "# Bootstrap aggregating (Bagging)\n",
    "\n",
    "\n",
    "\n",
    "* Apply the bootstrap procedure to tree\\-building:\n",
    "\n",
    "  * Create a bootstrap training set b from the original training set\n",
    "\n",
    "  * Grow a tree from b\n",
    "\n",
    "  * Repeat for all b in the set B of bootstrap samples\n",
    "\n",
    "  * To predict an outcome for a new data point x\\, predict for each tree\\, then average \\(For classification trees\\, each of the trees vote\\)\n",
    "\n",
    "\n",
    "\n",
    "# From bagging to random forests\n",
    "\n",
    "\n",
    "\n",
    "* We can go further with the randomization idea in bagging\\.\n",
    "\n",
    "* Idea behind both: lower variance in predictions by averaging over different trees\\.\n",
    "\n",
    "  * Bagging: Get different trees by randomizing sample\n",
    "\n",
    "  * Random forests: Bagging plus randomizing which variables you can split on\\.\n",
    "\n",
    "* Each time you go to split\\, only consider a randomly selected subset of variables\\, and choose the best split among those variables\\.\n",
    "\n",
    "\n",
    "\n",
    "# R and Python together\n",
    "\n",
    "\n",
    "\n",
    "# Related to a topic very close to me: How do we glue multiple models together?\n",
    "\n",
    "\n",
    "\n",
    "![](img\\\\1297.png)\n",
    "\n",
    "\n",
    "\n",
    "# Let's see!\n",
    "\n",
    "\n",
    "\n",
    "Open up 06\\_R\\_and\\_Python\\_together/01\\_combining\\_languages\\.ipynb\n",
    "\n",
    "\n",
    "\n",
    "# \n",
    "\n",
    "\n",
    "\n",
    "![](img\\\\1298.png)\n",
    "\n",
    "\n",
    "\n",
    "# From python for economists book\n",
    "\n",
    "\n",
    "\n",
    "<span style=\"color:#333333\">Incorporate </span>  <span style=\"color:#333333\">[https://aeturrell\\.github\\.io/coding\\-for\\-economists/coming\\-from\\-r\\.html](https://aeturrell.github.io/coding-for-economists/coming-from-r.html)</span>\n",
    "\n",
    "\n",
    "\n",
    "<span style=\"color:#333333\">For those coming from the '</span>  <span style=\"color:#333333\">tidyverse</span>  <span style=\"color:#333333\">' set of packages produced by RStudio\\, there are very direct Python equivalents\\. For example\\, Python has </span>  <span style=\"color:#333333\"> __plotnine__ </span>  <span style=\"color:#333333\"> which has the same syntax to R's </span>  <span style=\"color:#333333\"> __ggplot2__ </span>  <span style=\"color:#333333\">\\. There's also </span>  <span style=\"color:#333333\"> __plydata__ </span>  <span style=\"color:#333333\">\\, which has the same syntax as R's </span>  <span style=\"color:#333333\"> __dplyr__ </span>  <span style=\"color:#333333\"> package\\. In Python\\, </span>  <span style=\"color:#333333\"> __matplotlib__ </span>  <span style=\"color:#333333\"> and </span>  <span style=\"color:#333333\"> __pandas__ </span>  <span style=\"color:#333333\"> are more popular packages for plotting and data analysis\\, respectively\\, but those R\\-style packages are absolutely there if you prefer them\\. More on other similar packages below\\.</span>\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('8222env1')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 | packaged by conda-forge | (main, Nov 22 2022, 08:16:33) [MSC v.1929 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "0db313e0ad7b6749a6d098fb61fddaded88cbd823278030b75fa0893942c8f77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
